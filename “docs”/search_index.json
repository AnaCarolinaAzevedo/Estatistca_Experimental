[["index.html", "Apostila de Estatistica Experimental Capítulo 1 Introdução a Estatistica Experimental 1.1 Porque utilizar a Estatistica no cotidiano 1.2 Sobre a apostila", " Apostila de Estatistica Experimental Pedro Ivo 2024-08-30 Capítulo 1 Introdução a Estatistica Experimental A Estatística Experimental é essencial para cientistas, pesquisadores e profissionais de diversas áreas planejadas, conduzidas e analisadas em experimentos de maneira sistemática e objetiva. O objetivo central dessa disciplina consiste em compreender a variabilidade natural dos dados ao extrair insights válidos provenientes desses experimentos, o que garanta decisões embasadas em evidências confiáveis. Nos experimentos, atua desde o planejamento, onde se define o desenho experimental mais adequado, até a análise e interpretação dos resultados. Isso envolve a aplicação de técnicas que ajudam a identificar padrões, testar hipóteses e quantificar a incerteza relacionada às dúvidas. Em suma, é uma ferramenta indispensável para qualquer investigação científica que busque resultados precisos e replicáveis. 1.1 Porque utilizar a Estatistica no cotidiano A utilização da Estatística na nossa vida cotidiana permite-nos analisar informações com maior precisão, compreender incertezas específicas dos dados e evitar implicações precipitadas baseadas em percepções intuitivas ou visões cognitivas. Num mundo onde somos constantemente bombardeados por informação, a Estatística torna-se um escudo contra a desinformação, ajudando-nos a diferenciar entre verdadeiras coincidências e causalidades, suposições e fatos. Além disso, na esfera empresarial, a utilização da Estatística é necessária para maximizar os processos operacionais, garantir o controle de qualidade ao público-alvo e realizar pesquisas mercadológicas, além de estimar análises preditivas que fornecem orientações estratégicas. Em síntese, ela proporciona instrumentos mais precisos para tomadas de decisão otimizadas para melhorar os resultados corporativos, sobretudo no sentido de compreender melhor o mundo com maior profundidade em bases sólidas. 1.2 Sobre a apostila Esta apostila foi criada como um recurso didático para auxiliar o ensino de conceitos e técnicas da Estatística Experimental, utilizando a linguagem R como principal ferramenta para análise de dados. O objetivo é oferecer aos estudantes uma compreensão prática e aplicada da Estatística, por meio do uso do R em simulações, visualizações e análises que apresentam exemplos dos conceitos teóricos envolvidos. Ao longo dos capítulos, os fundamentos da Estatística Experimental são explorados juntamente com métodos avançados de análise. Exemplos práticos em R são fornecidos para ajudar os leitores a visualizar cada etapa envolvida nas técnicas estatísticas e aplicar seus conhecimentos de forma interativa. A combinação de teoria e aplicação prática usando R prepara os estudantes para problemas experimentais do mundo real, promovendo experiências de aprendizagem eficazes e significativas. Este material visa não apenas ensinar Estatística Experimental, mas também capacitar os alunos no uso do R como uma poderosa ferramenta analítica. Incentiva o desenvolvimento de competências analíticas cada vez mais valorizadas em vários campos de investigação e prática profissional. "],["teste-t-para-duas-médias.html", "Capítulo 2 Teste t Para Duas Médias 2.1 Teste t de Student para dois grupos ou médias independentes 2.2 A.Variâncias Homocedásticas 2.3 B. Variâncias Heterocedásticas", " Capítulo 2 Teste t Para Duas Médias 2.1 Teste t de Student para dois grupos ou médias independentes Consiste em uma comparação simples de dois tratamentos de um fator As amostras devem ser independentes Isso quer dizer que as unidades experimentais para cada tratamento são diferentes As variâncias populacionais não são conhecidas Adimite-se a presuposição de normalidade Deve ser verificada a homogeneidade das variâncias knitr::include_graphics(&quot;imagens/testes.png&quot;) 2.2 A.Variâncias Homocedásticas Os dados que seguem são relacionados a cinco determinações da resistência (mpa) para dois tipos de concreto. Ao nível de 5% de significância, há evidência de que a resistência entre os dois tipos de concretos é diferente? Os dados seguem abaixo: c1 &lt;-c(54,55,58,51,57); c1 ## [1] 54 55 58 51 57 c2 &lt;-c(50,54,56,52,53); c2 ## [1] 50 54 56 52 53 2.2.1 Análise Exploratória mean(c1) # Média c1 ## [1] 55 mean(c2) # Média c2 ## [1] 53 var(c1) # Variância c1 ## [1] 7.5 var(c2) # VAriância c2 ## [1] 5 2.2.2 Gráfico Box-Plot boxplot1 &lt;- boxplot(c1, c2) 2.2.3 Pressuposição de Normalidade shapiro.test(c1) ## ## Shapiro-Wilk normality test ## ## data: c1 ## W = 0.96358, p-value = 0.8327 shapiro.test(c2) ## ## Shapiro-Wilk normality test ## ## data: c2 ## W = 0.99929, p-value = 0.9998 2.2.4 Teste de Homogeneidade das Variâncias Teste F &gt; 1 unilateral à direita O primeiro vetor deve conter o conjunto de dados de maior variância! Ho: sig^2(1) = sig^2(2) Ha: sig^2(1) &gt; sig^2(2) var.test(c1, c2, alternative = &quot;greater&quot;) ## ## F test to compare two variances ## ## data: c1 and c2 ## F = 1.5, num df = 4, denom df = 4, p-value = 0.352 ## alternative hypothesis: true ratio of variances is greater than 1 ## 95 percent confidence interval: ## 0.2348067 Inf ## sample estimates: ## ratio of variances ## 1.5 gginference::ggvartest(var.test(c1, c2, alternative = &quot;greater&quot;)) ## Warning in geom_text(aes(x = ub, y = -0.025), label = round(ub, 3), vjust = 0.3): All aesthetics have length 1, but the data has 10000 ## rows. ## ℹ Please consider using `annotate()` or provide this ## layer with data containing a single row. 2.2.5 Teste t para variâncias homocedásticas H0: mu(1) = mu(2) Ha: mu(1) != mu(2) knitr::include_graphics(&quot;imagens/teste t (1).png&quot;) t.test(c1 , c2 ,alternative=&#39;two.sided&#39;, var.equal=TRUE) ## ## Two Sample t-test ## ## data: c1 and c2 ## t = 1.2649, df = 8, p-value = 0.2415 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -1.646113 5.646113 ## sample estimates: ## mean of x mean of y ## 55 53 2.2.6 Gráfico do teste t gginference::ggttest(t.test(c1 , c2 ,alternative=&#39;two.sided&#39;, var.equal=TRUE)) ## Warning: `geom_vline()`: Ignoring `data` because `xintercept` ## was provided. 2.3 B. Variâncias Heterocedásticas Os dados que seguem são relacionados a cinco determinações da resistência (mpa) para dois tipos de concreto. Ao nível de 5% de significância, há evidência de que o concreto 1 é mais resistente? Os dados seguem abaixo: c.1 &lt;- c(54,55,58,51,57); c.1 ## [1] 54 55 58 51 57 c.2 &lt;- c(40,34,56,72,63); c.2 ## [1] 40 34 56 72 63 2.3.1 Análise Exploratória mean(c.1); mean(c.2); var(c.1); var(c.2) ## [1] 55 ## [1] 53 ## [1] 7.5 ## [1] 250 2.3.2 Gráfico Box-Plot boxplot(c.1, c.2) 2.3.3 Pressuposição de Normalidade shapiro.test(c.1) ## ## Shapiro-Wilk normality test ## ## data: c.1 ## W = 0.96358, p-value = 0.8327 shapiro.test(c.2) ## ## Shapiro-Wilk normality test ## ## data: c.2 ## W = 0.94911, p-value = 0.7308 2.3.4 Teste de Homogeneidade das Variâncias Teste F &gt; 1 unilateral à direita O primeiro vetor deve conter o conjunto de dados de maior variância! Ho: sig^2(1) = sig^2(2) Ha: sig^2(2) &gt; sig^2(1) var.test(c.2 ,c.1,alternative=&#39;greater&#39;) # Vetor c.2 de maior variância ## ## F test to compare two variances ## ## data: c.2 and c.1 ## F = 33.333, num df = 4, denom df = 4, p-value = 0.002496 ## alternative hypothesis: true ratio of variances is greater than 1 ## 95 percent confidence interval: ## 5.217927 Inf ## sample estimates: ## ratio of variances ## 33.33333 gginference::ggvartest(var.test(c.2 ,c.1,alternative=&#39;greater&#39;)) ## Warning in geom_text(aes(x = ub, y = -0.025), label = round(ub, 3), vjust = 0.3): All aesthetics have length 1, but the data has 10000 ## rows. ## ℹ Please consider using `annotate()` or provide this ## layer with data containing a single row. 2.3.5 Teste t para variâncias heterocedásticas H0: mu(1) = mu(2) Ha: mu(1) &gt; mu(2) knitr::include_graphics(&quot;imagens/teste t (2).png&quot;) t.test(c.1, c.2, alternative=&#39;greater&#39;, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: c.1 and c.2 ## t = 0.27869, df = 4.2398, p-value = 0.3968 ## alternative hypothesis: true difference in means is greater than 0 ## 95 percent confidence interval: ## -13.05363 Inf ## sample estimates: ## mean of x mean of y ## 55 53 2.3.6 Gráfico do teste t library(gginference) gginference::ggttest(t.test(c.1 , c.2 ,alternative=&#39;greater&#39;, var.equal=TRUE)) ## Warning in geom_text(aes(x = ub, y = -0.02), label = round(ub, 3), vjust = 0.3): All aesthetics have length 1, but the data has 10000 ## rows. ## ℹ Please consider using `annotate()` or provide this ## layer with data containing a single row. "],["anova---delineamento-inteiramento-casualizado.html", "Capítulo 3 ANOVA - Delineamento Inteiramento Casualizado 3.1 Introdução 3.2 Modelo Estatístico 3.3 Análise de Variância 3.4 Análise das Pressuposições 3.5 Coeficiente de Variação Experimental", " Capítulo 3 ANOVA - Delineamento Inteiramento Casualizado 3.1 Introdução O Delineamento Inteiramente Casualizado (DIC) é o de mais simples aplicação Utilizado quando temos um único fator em análise e seus diferentes níveis ou grupos (tratamentos) Consiste na casualização completa dos tratamentos às unidades experimentais Envolve os seguintes princípios experimentais: Repetição Casualização Não há blocagem ou controle local pois as unidades experimentais são homogêneas Exemplo Um fabricante de papel está interessado em melhorar a qualidade do seu produto. A engenharia do produto pensa que a resistência à tração seja uma função da concentração de celulose na madeira e a que a faixa prática de interesse das concentrações esteja entre 5 e 20%. Um grupo de engenheiros responsáveis pelo estudo decide investigar quatro níveis de concentração: 5, 10, 15 e 20 %. Eles decidem fabricar seis corpos de prova para cada nível de concentração, usando uma planta piloto. Todos os 24 corpos de prova são testados, em uma ordem aleatória, em um equipamento de teste de laboratório, em que é mensurada a resistência à tração (psi=libra/polegada2). Verifique se a concentração de celulose apresenta efeito siginifcativo na resistência à tração (alfa = 5%). Os dados desse experimento são mostrados a seguir. 3.1.1 Interpretação O que nós estamos testando? Qual o objetivo do experimento? Verificar o efeito da concentração de celulose da madeira na resistência à tração do papel. Concentração de celulose: Variável Independente (1 Fator em estudo) Quatro níveis (5, 10, 15 e 20) ou Quatro tratamentos Natureza da variável: Quantitativa Resistência à tração: Variável Resposta (Quantitativa) Natureza da variável: Quantitativa Caracterização: I = 4 tratamentos J = 6 repetições N = I*J = 24 unidades experimentais 3.1.2 Dados Tabela 1. Resistência (psi) à tração do papel em função da concentração de madeira de lei (%) knitr::include_graphics(&quot;imagens/tabela dic.png&quot;) 3.1.3 Input de Dados Podemos importar o data set a partir de um documento txt Nessa operação vamos criar um data-frame com dois vetores conc_%: vetor da variável independente r_trac: vetor da variável resposta dados &lt;- read.table(&quot;dados/ex_01_dic.txt&quot;, header = TRUE) head(dados) ## conc trac ## 1 5 7 ## 2 5 8 ## 3 5 15 ## 4 5 11 ## 5 5 9 ## 6 5 10 3.1.4 Estrutura do Data-Frame Podemos verificar a estrutura do nosso data-frame str(dados) ## &#39;data.frame&#39;: 24 obs. of 2 variables: ## $ conc: int 5 5 5 5 5 5 10 10 10 10 ... ## $ trac: int 7 8 15 11 9 10 12 17 13 18 ... Para a ANOVA temos que transformar o vetor da variável independente em fator dados$conc &lt;- as.factor(dados$conc) str (dados) ## &#39;data.frame&#39;: 24 obs. of 2 variables: ## $ conc: Factor w/ 4 levels &quot;5&quot;,&quot;10&quot;,&quot;15&quot;,..: 1 1 1 1 1 1 2 2 2 2 ... ## $ trac: int 7 8 15 11 9 10 12 17 13 18 ... 3.1.5 Análise Gráfica Exploratória Histograma da distribuição da variável resposta: hist1 &lt;- hist(dados$trac) Box-Plot da variável resposta em função dos tratamentos boxplot(trac ~ conc, data= dados) Um gráfico dot-plot mais elaborado com base no pacote ggplot2: library(ggplot2) ggplot(dados, aes(x = conc, y = trac)) + geom_dotplot(binaxis = &#39;y&#39;, stackdir = &#39;center&#39;, dotsize = 0.5) + stat_summary(fun.data = mean_sdl, fun.args = list(mult = 1), geom = &quot;pointrange&quot;, colour = &quot;red&quot;) + theme_classic() 3.2 Modelo Estatístico 3.2.1 Modelo Estatístico (1) É um modelo linear: yij = mu + ti + eij Onde: yij = observação da variável resposta para o i-ésimo tratamento e a j-ésima repetição; mu = média geral; ti = efeito do i-ésimo tratamento; eij = erro experimental com a pressuposição eij ~ NID(0; sigma^2) Significa que vamos decompor as observações (dados coletados) no efeito da média geral, dos tratamentos e do erro experimental 3.2.2 Modelo Estatístico (2) É um sistema de equações lineares: yij = mu + ti + eij 7 = 15.96 + -5.96 + -3.00 8 = 15.96 + -5.96 + -2.00 15 = 15.96 + -5.96 + 5.00 … Veja que: mi = mu + ti ti = mi - mu eij = yij - mi 3.3 Análise de Variância 3.3.1 Análise de Variância (1) Para resolver o problema da análise de médias para dois ou mais grupos utilizamos a Análise de Variância Vamos testar a hipótese: Ho: m1 = m2 = m3 = m4 = mu Isso corresponde a dizer que não existe o efeito de tratamentos no modelo e todas as médias são estatisticamente iguais à média geral A hipótese alternativa pode ser dada por: Ha: Pelo menos uma média é diferente das demais Ou seja, existe influência do efeito de tratamentos no modelo. Pela ANOVA não podemos saber diretamente aonde estão estas diferenças. Mas “algo” está acontecendo em relação aos tratamentos testados 3.3.2 Análise de Variância (2) A técnica da ANOVA é uma decomposição da variância total nas variâncias dos efeitos do modelo. Veja a figura abaixo: knitr::include_graphics(&quot;imagens/anova.png&quot;) Figura. A técnica da ANOVA consiste em investigar as variâncias do modelo, através de uma descomposição de variâncias. A variância total é relativa à média geral (na figura ‘Grand Mean’). A variância dos tratamentos é a relação entre as médias dos tratamentos (‘Among Group Variance’) e a média geral. A variância residual (devida ao Erro Experiomental) é a variância dentro dos grupos de médias (‘Within Group Variance’), que consiste nos desvios de cada observação em relação à média de cada grupo (ou média de cada tratamento) 3.3.2.1 Decomposição das Somas de Quadrados (SQ) Sabemos que uma variância pode ser calculada por: S2 = SQD / gl Em que: SQD = Soma de Quadrados de Desvios gl = Graus de Liberdade Portanto, vamos iniciar a decomposição via Somas de Quadrados (SQ) para cada efeito do modelo: yij = m + ti + eij SQTotal = SQTrat + SQRes SQTotal = ∑(yij - mu)2 (Desvios Quadráticos das observações em relação à média geral) SQTrat = J∑(mi - mu)2 (Desvios Quadráticos das médias de tratamentos em relação à média geral) SQRes = ∑(yij - mi)2 (Desvios Quadráticos das observações em relação às médias de tratamentos) knitr::include_graphics(&quot;imagens/sq_figura.png&quot;) Figura. Exemplo de decomposição das Somas de Quadrados de um modelo estatístico no DIC. A Soma de Quadrados do Total (SQTotal) permite calcular os desvios quadráticos entre cada observação (yij) e a média geral (mu). A Soma de Quadrados de Tratamentos (SQTRat), que corresponde a variação entre grupos (Between Groups), consiste em calcular os desvios quadráticos das médias dos tratamentos (mi) e a média geral, permitindo computar a variação devido aos efeitos dos tratmentos. A Soma de Quadrado Residual (Dentro de Grupos) envolve o cálculo dos desvios de cada observação em relação à média dos tratamentos. Estes desvios correspondem à uma estimativa da variação do erro experimental. 3.3.3 Análise de Variância (3) ANOVA é uma decomposição das variâncias do modelo O que é uma variância? S2 = SQD / gl Já temos as Somas de Quadrados calculadas. Portanto, devemos calcular os Graus de Liberdade (gl) para cada fonte de variação do modelo: gl(Total) = I*J - 1 = N - 1 = 24 - 1 = 23 gl(Trat) = I - 1 = 4 - 1 = 3 gl(Res) = gl(Res) = gl(Total) - gl(Trat) = 23 - 3 = 20 3.3.4 Análise de Variância (4) Finalmente podemos calcular as variâncias para as fontes de variação do efeitos do modelo. Basta dividir as SQ pelo número de graus de liberdade correspondente: Na ANOVA vamos chamar as variâncias de Quadrados Médios QMTotal = SQTotal / gl(Total) QMTrat = SQTrat / gl(Trat) QMRes = SQRes / gl(Res) Agora vamos utilizar o teste F para verificar se a variância dos efeitos de tratamentos (QMTrat) é maior do que a variância resiual ou do erro experimental (QMRes): F = QMTrat / QMRes 3.3.5 Análise de Variância (5) A ANOVA pode ser realizada através de um comando simples no R modelo &lt;- aov(trac ~ conc, data = dados) # Ajuste do Modelo anova(modelo) # Obter a tabela da ANOVA ## Analysis of Variance Table ## ## Response: trac ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 3 382.79 127.597 19.605 3.593e-06 *** ## Residuals 20 130.17 6.508 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 O F calculado de F = 19,6 indica que o QMTrat (que é a variância dos efeitos dos tratamentos) é 19 vezes maior que o QMRes (Variância do Erro Experimental) Associado a este valor de F, temos o p-valor = 3.593e-06 muito reduzido. Os três asteriscos indicam que estamos rejeitando a hipótese H0 com um alfa próximo de 0% de probabilidade. Entretanto, o ideal é estabelcer um alfa previamente, que é probabildiade de erro tipo I (falso positivo). No exemplo, adimtimos um alfa = 0,05. Logo rejeitamos Ho: m1 = m2 = m3 = m4 = mu Portanto podemos concluir que os efeitos dos tratamentos apresentam uma grande contribuição em relação à variação total e superior aos efeitos do erro experimental. Podemos dizer que os efeitos dos tratamentos (ti) exerce uma influência significativa na resistência à tração e o nosso modelo explica bem a variação dos dados! Uma conclusão textual: “Pode-se verificar que as concetração de celulose na madeira apresenta efeito ‘significativo’ na resistência à tração do papel (alfa = 0,05)” 3.3.5.1 Interpretação do Teste F na ANOVA Podemos interpretar o teste F da seguinte forma: knitr::include_graphics(&quot;imagens/Fvalue1.jpeg&quot;) Figura. Quando o valor da estatística F = QMTrat/QMRes é baixo, as diferenças entre as médias dos tratamentos são pequenas em relação à variação residual. O ‘tamanho’ dessas diferenças é medido indiretamente pelo QMTrat. Nesse caso, o valor-p &gt; alfa, levando à não rejeição de H0. Ou seja, nessas condições experimentais não é possível captar a influência dos tratamentos sobre a variável resposta. knitr::include_graphics(&quot;imagens/Fvalue2.jpeg&quot;) Figura. Quando o valor da estatística F = QMTrat/QMRes é alto, as diferenças entre as médias dos tratamentos são grandes em relação à variação residual. Nesse caso, o valor-p &lt; alfa, levando à rejeição de H0. Ou seja, nessas condições experimentais é possível captar a influência dos tratamentos sobre a variável resposta, como é o caso do exemplo tabalhado. 3.3.6 Análise de Variância (6) Podemos explorar de outra forma os resultados, considerando um modelo linear com suas inclinações modelo2 &lt;- lm(trac ~ conc, data = dados) # Modelo Linear com inclinação summary(modelo2) # Obter efeitos do modelo ## ## Call: ## lm(formula = trac ~ conc, data = dados) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.667 -2.042 0.000 1.458 5.000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.000 1.041 9.602 6.24e-09 *** ## conc10 5.667 1.473 3.847 0.001005 ** ## conc15 7.000 1.473 4.753 0.000122 *** ## conc20 11.167 1.473 7.581 2.65e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.551 on 20 degrees of freedom ## Multiple R-squared: 0.7462, Adjusted R-squared: 0.7082 ## F-statistic: 19.61 on 3 and 20 DF, p-value: 3.593e-06 anova(modelo2) # Obter a tabela da ANOVA ## Analysis of Variance Table ## ## Response: trac ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 3 382.79 127.597 19.605 3.593e-06 *** ## Residuals 20 130.17 6.508 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 3.4 Análise das Pressuposições 3.4.1 Análise das Pressuposições (1) Para validar o teste F, temos que estudar as pressuposições do modelo, que estão associadas ao erro experimental ou resíduo: eij ~ NID(0;sigma2) Normalidade dos Resíduos Independência dos Erros Homogeneidade das Variâncias 3.4.2 Análise das Pressuposições (2) Análise Gráfica de Resíduos (ou Análise de Resíduos) Para avaliar a homogeneidade das variâncias, utilizamos o gráfico de Valores Ajustados vs Resíduos plot(modelo, 1) Figura. Neste gráfico podemos observar a dispersão dos valores residuais em relação aos valores ajustados (‘Fited values’). Os valores ajustados são exatamente os valores das médias de tratamentos. Agora, nosso modelo é um modelo de predição, dado apenas por ‘yij = mi’. Nesse gráfico observamos a relação da variância dos resíduos (sigma2) para cada tratamento. Se as variâncias do erros são homogêneas, a dispersão dos erros para cada tratamento é próxima. Também podemos avaliar essa homogeneidade com base em um box-plot dos resíduos em função dos tratamentos, conforme a figura abaixo: boxplot(resid(modelo)~ conc, data = dados) Outra análise gráfica pode ser feita através do gráfico Quantil-Quantil Normal, que verifica a normalidade dos resíduos. plot(modelo, 2) Figura. Neste gráfico os valores dos resíduos padronizados devem estar o mais próximo possível da linha teórica da normalidade. Quanto mais próximo, melhor o ajuste à normalidade 3.4.3 Análise das Pressuposições (3) A análise das pressuposções também pode ser feita através de testes estatísticos: Testes para Normalidade dos Resíduos (Teste de Shapiro-wilk) H0: eij ~ Normal Teste de Homogeneidade de Variâncias (Teste de Bartlett) H0: Variâncias Homogêneas shapiro.test(resid(modelo)) ## ## Shapiro-Wilk normality test ## ## data: resid(modelo) ## W = 0.96624, p-value = 0.5757 bartlett.test(trac ~ conc, data = dados) ## ## Bartlett test of homogeneity of variances ## ## data: trac by conc ## Bartlett&#39;s K-squared = 1.1352, df = 3, p-value = 0.7686 3.4.4 Análise das Pressuposições (4) O que fazer quando as pressuposições não são atendidas? Verificar a qualidade dos dados (presença de outliers) Testar algum tipo de transformação de dados na variável resposta Utilizar um teste não-paramétrico (‘Livre de Pressuposições’) Utilizar um Modelo Linear Generalizado para testar outras distribuições de resíduos, além da distribuição Normal (Ex: Binomial, Poisson, Gama, etc.) Se as violações não são graves, a ANOVA é robusta e o teste F ainda apresenta boas propriedades 3.5 Coeficiente de Variação Experimental Permite avaliar a precisão do experiemnto: CV = 100 * Raiz(QMRes)/Média Geral library(agricolae) cv.model(modelo) ## [1] 15.98628 O CV pode ser interpretado da seguinte forma: CV &lt; 10%: Alta precisão expreimental 10% &lt; CV &lt; 20%: Média precisão experimental 20% &lt; CV &lt; 30%: Baixa precisão experimental CV &gt; 30%: Muito baixa precisão experimental "],["delineamento-em-blocos-casualizados.html", "Capítulo 4 Delineamento em Blocos Casualizados 4.1 Introdução 4.2 Casualização em DBC 4.3 Modelo Estatístico 4.4 Análise de Variância 4.5 Análise no R", " Capítulo 4 Delineamento em Blocos Casualizados 4.1 Introdução O Delineamento em Blocos Casualizados (DBC) envolve os seguintes princípios experiemntais: Repetição Casualização Blocagem Blocagem (Controle da Casualização): Também conhecido como “Controle Local” Aplicado quando as condições experimentais não são homogêneas em todas as unidades experimentais Ou seja, existe algum nível de variação sistemática (fatores externos) que pode ser reconhecida no experimento Exemplos: Na Agronomia: Em estudos que são feitos a campo. Blocos são faixas do solo que apresentam maior homogeneidade. (Blocagem no espaço, como controle local). Na indústria: Diferentes lotes de produção podem apresentar variações (matéria-prima, máquinas diferentes da unidade de produção, etc) Controle de qualidade da produção. (Blocagem em termos de lotes de produção) No laboratório: Variações de material experimental, coletas, reagentes, etc. Em ensaios clínicos (idade, peso, sexo, etc). Dias diferentes de análise. Nestas condições o DBC torna-se mais eficiente do que o DIC: Redução de Variabilidade Residual: Uma vez que as UE são organizadas em blocos homogêneos Controle da Variação Sistemática: O efeito de blocos é computado no experimento e no modelo de análise Aumento da Precisão: As comparações entre tratamentos são realizadas com maior precisão uma vez que a diferença entre os blocos é controlada 4.2 Casualização em DBC A casualização é realizada de forma independente em cada bloco Todos os tratamentos devem aparecer em cada bloco n° blocos = n° repetições Atenção! Se não é possível alocar todos os tratamentos dentro dos blocos temos um Delineamento de Blocos Incompletos Não será abordado nesta disciplina! Exemplo Suponha um experimento com três tratamentos e cinco repetições. No DBC cada bloco constituirá uma repetição. Em cada bloco deverá constar uma repetição de cada tratamento. Dentro de cada bloco os tratamentos deverão ser dispostos de forma casualizada. Esquematicamente o DBC fica caracterizado conforme a figura abaixo: Exemplo2 Os dados abaixo referem-se a um experimento instalado segundo o DBC. Foram testados 5 produtos comerciais para suprir a deficiência nutricional em caprinos. As unidades experimentais foram separadas em 3 grupos segundo a idade dos animais. Dentro de cada grupo os produtos foram distribuídos de maneira casualizada. Os resultados obtidos são expressos em ppm de nutriente/ml de sangue. Pede-se proceder a ANOVA e verificar a significância dos efeitos de tratamentos (Alfa=0,05). Interpretação Variável Independente ou Fator em Estudo: Produtos Comerciais (I = 5 níveis ou tratamentos) Variável Qualitatitva Blocos: Grupos de Idade (J = 3 blocos = 3 repetições) Variável Qualitativa Número de Unidades Experimentais N = I*J = 15 4.3 Modelo Estatístico yij = mu + ti + bj + eij Onde: yij = observação da variável resposta para o i-ésimo tratamento e a j-ésima repetição; mu = média geral; ti = efeito do i-ésimo tratamento; bj = efeito do j-ésimo bloco; eij = erro experimental com a pressuposição eij ~ NID(0; sigma2) 4.4 Análise de Variância Vamos testar as hipóteses: H0: m1=m2=m3=m4=m5 Ha: Pelo menos uma média é diferente das demais A técnica da ANOVA é uma decomposição da variância total nas variâncias dos efeitos do modelo. Portanto, vamos podemos realizar a decomposição por meio das Somas de Quadrados (SQ) para cada efeito (fonte de variação) do modelo : yij = m + ti + bj + eij SQTotal = SQTrat + SQBlocos + SQRes Na sequência podemos calcular os graus de liberdade relativos a cada fonte de variação do modelo: Graus de Liberdade: gl(Total): N - 1 = 14 gl(Tratamentos): I - 1 = 4 gl(Blocos): J - 1 = 2 gl(Res) = gl(Total) - gl(Trat) - gl(Blocos) = 8 Finalmente, os Quadrados Médios podem ser obtidos para cada fonte de variação do modelo: QMTrat = SQTrat/gl(Trat) QMBlocos = SQBlocos/gl(Blocos) QMRes = SQRes/gl(Res) Os QM são as variâncias relativas a cada efeito do modelo. O Teste F permite verificar se o efeito dos tratamentos é mais importante que a variação residual F = QMTrat/QMRes 4.5 Análise no R A Análise de Variância em um DBC pode ser executada facilmente no R. 1. Input de Dados Podemos fazer a importação da base de dados através do comando read.table dados1 &lt;- read.table(&quot;dados/dados_dbc.txt&quot;, h = TRUE) dados1 ## trat bloco y ## 1 1 1 83 ## 2 1 2 63 ## 3 1 3 55 ## 4 2 1 86 ## 5 2 2 69 ## 6 2 3 61 ## 7 3 1 103 ## 8 3 2 79 ## 9 3 3 79 ## 10 4 1 116 ## 11 4 2 81 ## 12 4 3 79 ## 13 5 1 132 ## 14 5 2 98 ## 15 5 3 91 Uma rápida inspeção no dataframe nos indica que os vetores para tratamentos e blocos são números inteiros. Portanto, é necessário transfomá-los em fatores: dados1 &lt;- transform(dados1, trat = factor(trat), bloco = factor(bloco)) Veja que também podemos realizar essa transdormação por meio dos comandos abaixo: dados1$trat &lt;- as.factor(dados1$trat) dados1$bloco &lt;- as.factor(dados1$bloco) 2. Análise Exploratória Podemos iniciar a análise exploratória visualizando um histograma dos valores da variável resposta: par(mfrow=c(2,1)) hist2 &lt;- hist(dados1$y) boxplot(dados1$y, horizontal = TRUE) Pelo histograma não podemos ter certeza de uma distribuição normal, porém também não podemos descartar essa possibilidade O gráfico boxplot também nos dá alguns indicadores da distribuição dos dados Também podemos obter um boxplot para cada tratamento boxplot(y ~ trat, data = dados1, horizontal=TRUE) boxplot(y ~ bloco, data = dados1, horizontal=TRUE) boxplot(y ~ trat, data = dados1) A princípio a ditribuição dos dados parece ser homogênea entre os tratamentos O tratamento 5 exibe uma maior variação O tratamento 3 parece ser mais assimétrico Pela análise exploratória, podemos verificar que os dados em questão não devem apresentar violações graves das pressuposições do modelo. Iremos confirmar isso na análise de resíduos após a ANOVA 3. Análise de Variância É de fácil aplicação através do comando aov A função summary permite visualizar a tabela da ANOVA modelo1 &lt;- aov(y ~ trat + bloco, data = dados1) summary(modelo1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trat 4 3090 772.5 33.59 4.76e-05 *** ## bloco 2 2770 1385.0 60.22 1.51e-05 *** ## Residuals 8 184 23.0 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 modelo2 &lt;- aov(y ~ trat, data = dados1) summary(modelo2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## trat 4 3090 772.5 2.615 0.0992 . ## Residuals 10 2954 295.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 O p-valor associado ao valor de Fcal para o efeito de tratamentos indica que podemos resjeitar a hipótese de nulidade de que as médias dos tratamentos seja iguais De fato, o QMTrat (772,5) é bem maior que o QMRes (23,0) Veja também que o efeito de blocos, ou seja, a variação entre os blocos também é alta. Embora não haja um interesse específico nessa variação, isso indica, de certa forma, que estamos corretos em organizar nosso experimento em blocos casualizados Uma interpretação final pode ser dada para o resultado da ANOVA: “A ANOVA indica que os produtos comercias testados exercem efeito significativo na concentração do nutriente no sangue (p &lt;0,05)” 4. Análise de Pressuposições Mais uma vez precisamos realizar a análise das pressuposições do erro experimental: eij ~ NID(0;Sigma2) Podemos fazer isso graficamente: plot(modelo1, c(1,2)) Além da análise gráfica, podemos utilizar: Teste de Shapiro-Wilk (Normalidade) Teste de Bartlett (Homogeneidade de Variâncias) shapiro.test(resid(modelo1)) ## ## Shapiro-Wilk normality test ## ## data: resid(modelo1) ## W = 0.9285, p-value = 0.2591 bartlett.test(resid(modelo1) ~ trat, data= dados1) ## ## Bartlett test of homogeneity of variances ## ## data: resid(modelo1) by trat ## Bartlett&#39;s K-squared = 0.63055, df = 4, p-value = 0.9596 5.Coeficiente de Variação Experimental Finalmente podemos interpretar o coeficiente de variação experimental library(agricolae) cv.model(modelo1) ## [1] 5.642155 "],["contrastes-tcm.html", "Capítulo 5 Contrastes TCM 5.1 Introdução", " Capítulo 5 Contrastes TCM 5.1 Introdução "],["regressão-linear.html", "Capítulo 6 Regressão Linear 6.1 Regressão Linear Simples", " Capítulo 6 Regressão Linear 6.1 Regressão Linear Simples A análise de Regressão Linear Simples pode envolver dois cenários, a depender da estrutura de dados utilizada. Um primeiro caso, bastante típico, correponde em se utilizar apenas uma única observação para cada nível da variável independente X. Isso corresponderia a um experimento sem repetições, uma vez que cada nível da variável independente corresponde a um tratamento. Em geral, no caso de análise de dados oriundos de um experimento, o que os pesquisadores fazem é calcular a média de cada tratamento, tomando estes valores como uma observação única. Um segundo caso é considerarmos todas as observações ou repetições na Análise de Regressão. Este caso é mais desafiador em termos analíticos. Porém, permite uma análise mais cuidadosa do ajuste do modelo, através da Análise da Falta de Ajuste. Vamos abordar estes dois casos a seguir. 6.1.1 Observação única para cada nível da variável X Exemplo 1: Um estudo foi conduzido para verificar a dilatação em barras de aço. Para tanto, foram testadas diferentes temperaturas (°C) e medidos os comprimentos (mm) das barras de aço. Pede-se ajustar um modelo de Regressão Linear Simples. A primeira etapa é realizar a importação do dataset. dados3 &lt;- read.table(&quot;dados/reg.txt&quot;, h = T) dados3 ## temp comp ## 1 10 1003 ## 2 15 1005 ## 3 20 1010 ## 4 25 1011 ## 5 30 1014 Na Análise de Regressão, a investigação de um gráfico de dispersão nos dá uma idéia do relacionamento entre as variáveis. Nesse caso, a variável independente (x) é a temperatura e a variável resposta (y) é o comprimento das barras plot(x = dados3$temp, y = dados3$comp) Pela análise gráfica, verificamos que é bem provável existir uma relação linear simples entre as variáveis. Portanto vamos ajustar um modelo linear do tipo: \\[y_{i}=\\beta _{0}+\\beta _{1}x_{i}+\\epsilon\\] Este ajuste pode ser facilmente obtido usando a função lm reg1 &lt;- lm(comp ~ temp, data = dados3) reg1 ## ## Call: ## lm(formula = comp ~ temp, data = dados3) ## ## Coefficients: ## (Intercept) temp ## 997.40 0.56 Como resultado, temos em mãos os coeficientes b0 e b1, estimados pelo método dos mínimos quadrados, de maneira que a equação ajustada fica: \\[\\hat{y}=997.40 +0.56x\\] - Embora tenhamos um modelo ajustado, é importante avaliar se este modelo apresenta boas propriedades estatísticas Uma primeira providência é realizar a análise das pressuposições dos resíduos do modelo: Linearidade Normalidade Homodecasticidade A análise gráfica dos resíduos pode ser facilmente implementada: par(mfrow=c(2,2)) plot(reg1) shapiro.test(resid(reg1)) ## ## Shapiro-Wilk normality test ## ## data: resid(reg1) ## W = 0.86775, p-value = 0.2574 Além da análise das presuposições, precisamos verificar também a significância do modelo e dos coefiicentes estimados b0 e b1. É possível avaliar estas propriedades de diferentes formas: ANOVA da Regressão com a função anova anova5 &lt;- anova(reg1); anova5 ## Analysis of Variance Table ## ## Response: comp ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## temp 1 78.4 78.400 84 0.002746 ** ## Residuals 3 2.8 0.933 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 A Tabela da ANOVA da Regressão permite testar a significância da equação ajustada. Algumas interpretações importantes: O F calculado é a razão entre o QMReg/QMRes. Este valor, sendo significativo, como é o caso, implica em verificar se os coeficientes são diferentes de zero. As hipóteses a serem testadas são: H0: b0 = b1 = 0 Ha: Pelo menos um bi diferente de zero O resultado obtido indica que a equação ajustada apresenta efeito singinficativo (p = 0,002746), ou seja, a variação explicada pelo modelo é mais importante que a variação residual Teste t para coeficientes com a função summary summary(reg1) ## ## Call: ## lm(formula = comp ~ temp, data = dados3) ## ## Residuals: ## 1 2 3 4 5 ## -9.008e-14 -8.000e-01 1.400e+00 -4.000e-01 -2.000e-01 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 997.4000 1.2961 769.511 4.84e-09 *** ## temp 0.5600 0.0611 9.165 0.00275 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9661 on 3 degrees of freedom ## Multiple R-squared: 0.9655, Adjusted R-squared: 0.954 ## F-statistic: 84 on 1 and 3 DF, p-value: 0.002746 Podemos verificar algumas estatísticas importantes: O teste t para os coeficientes da regressão implica em testar as hipóteses de que os coeficientes são iguais a zero ou não na forma de: H0: bi \\(=\\) 0 Ha: bi \\(\\neq\\) 0 O resultado indica que os dois coeficientes apresentam significância, indicando que os mesmos são diferentes de zero. A principal implicação prática refere-se ao coeficiente b1. Caso o teste t seja não significativo, este coeficiente tem inclinação zero e, portanto, teríamos uma situação em que a variação de x não exerce influencia sobre a variação em y Outro resultado prático é a interpretação do valor de R2, conhecido como Coeficiente de Determinação O R2 pode ser obtido por: \\[R^{2}= \\frac{SQReg}{SQTotal}\\] O R2 = 0,9655 indica que o modelo utilizado explica 96,55% da variação observada em y, indicando uma qualidade de ajuste muito boa. É importante ressaltar que o R2 varia de 0 &lt; R2 &lt; 1 Um próximo passo é criar o gráfico de dispersão para incluir a reta da equação ajustada. Vamos fazer isso de duas maneiras. Utilizando as funções básicas do R: plot(x = dados3$temp, y = dados3$comp, ylab = &quot;Comprimento (mm)&quot;, xlab = &quot;Temperatura (C)&quot;) abline(reg1, col=&quot;red&quot;) Utilizando o pacote ggplot2: #install.packages(&quot;ggplot2&quot;) library(ggplot2) ggplot(dados3, aes(temp, comp)) + geom_point() + geom_smooth(method=&#39;lm&#39;, se=TRUE) + labs(x=&quot;Temperatura (C)&quot;, y=&quot;Comprimento (mm)&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; 6.1.2 Mais de uma observação (repetições) para cada nível da variável X Uma situação mais comum em Delineamentos Experimentais é trabalhar com dados com repetição. Sendo assim os procedimentos são: Realizar a ANOVA do Delineamento Experimental de forma convencional Na sequência, realizar a Análise de Regressão, levando em consideração a Análsie da Falta de Ajuste É importante destacar que vamos empregar uma técnica denominada de Regressão Polinomial, em que é possível ajustar uma equação de grau n do tipo: \\[y_{i}=\\beta _{0}+\\beta _{1}x_{i}+\\beta _{2}x_{i}^2+...+\\beta _{n}x_{i}^n+\\epsilon\\] A Regressão Polinomial pode ser útil quando existe uma relação não linear clara entre as varáveis. Exemplo 2: Em um experimento no DIC com cinco repetições foram testadas cinco doses de um hormônio vegetal (15, 20, 25, 30 e 35 ppm), e seu efeito na indução de resistência a um inseto praga. A variável resposta indica o número de insetos praga encontrados em cada parcela. Input de Dados dados4 &lt;- read.table(&quot;dados/reg_2022.txt&quot;, h = T) dados4 ## conc resist ## 1 15 7 ## 2 15 7 ## 3 15 15 ## 4 15 11 ## 5 15 9 ## 6 20 12 ## 7 20 17 ## 8 20 12 ## 9 20 18 ## 10 20 18 ## 11 25 14 ## 12 25 18 ## 13 25 18 ## 14 25 19 ## 15 25 19 ## 16 30 19 ## 17 30 25 ## 18 30 22 ## 19 30 19 ## 20 30 23 ## 21 35 7 ## 22 35 10 ## 23 35 11 ## 24 35 15 ## 25 35 11 Análise Exploratória Por se tratar de um fator quantitativo, podemos fazer uma análise exploratória simples por meio de um gráfico de dispersão plot(resist ~ conc, data = dados4) A análise gráfica não parece retratar um modelo linear simples. A distribuição dos dados parece indicar um relação de 2 grau entre as variáveis. As análises estatísticas subsequentes vão nos ajudar a tomar essa decisão. ANOVA do Delineamento Experimental Como o vetor de tratamentos é numérico, será necessário criar um vetor de fatores auxiliar para a ANOVA dados4$concf &lt;- as.factor(dados4$conc) Na sequência realiza-se a ANOVA, conforme já conhecemos, utilizando o vetor adicional criado mod &lt;- aov(resist ~ concf, data = dados4) anova(mod) ## Analysis of Variance Table ## ## Response: resist ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## concf 4 475.76 118.94 14.757 9.128e-06 *** ## Residuals 20 161.20 8.06 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Com base no resultado, verificamos a significância dos efeitos das doses (p &lt; 0,05), implicando em uma análise de regressão complementar Podemos também realizar a Análise de Resíduos para as pressuposições do modelo: par(mfrow=c(2,2)) plot(mod) shapiro.test(resid(mod)) ## ## Shapiro-Wilk normality test ## ## data: resid(mod) ## W = 0.94387, p-value = 0.1818 Análise de Regressão - Modelo de 1° Grau Teremos que realizar um ajuste simultâneo para os tratamentos e a equação de regressão. O que fazemos aqui é ajustar um modelo de 1° grau incluindo os tratamentos e, em seguida, aplicar uma ANOVA ao modelo. Colocamos o termo adicional dosef para tratamentos ar1 &lt;- aov (lm (resist ~ conc + concf, data = dados4)) summary(ar1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 1 33.6 33.62 4.171 0.0545 . ## concf 3 442.1 147.38 18.285 5.97e-06 *** ## Residuals 20 161.2 8.06 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Compare o resultado com a ANOVA do Delineamento Experimental Inicialmente temos quatro graus de liberdade para tratamentos A fonte de variação dosecorresponde ao modelo de 1° Grau e consome um grau de liberdade dos tratamentos A fonte de variação dosefcorresponde ao que chamamos de Falta de Ajuste (ou Desvios de Regressão) e constitue os graus de liberdade restantes Veja que as Somas de Quadrados também podem ser somadas, indicando uma decomposição ortogonal Veja que o teste F para dose não é significativo a 5%. Isso indica que o modelo de 1° Grau não é adequado Além disso, o teste F para a Falta de Ajuste é significativo, ou seja, existe variação não captada pelo modelo de 1° Grau Sendo assim, convém testar o modelo de 2° Grau Análise de Regressão - Modelo de 2° Grau Nesse caso, vamos ajustar um modelo do tipo: \\[y_{i}=\\beta _{0}+\\beta _{1}x_{i}+\\beta _{2}x_{i}^2+\\epsilon\\] ar2 &lt;- aov (lm (resist ~ conc + I(conc^2) + concf, data = dados4)) # I(conc^2) corresponde ao termo quadrático summary(ar2) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 1 33.6 33.6 4.171 0.05452 . ## I(conc^2) 1 343.2 343.2 42.582 2.33e-06 *** ## concf 2 98.9 49.5 6.137 0.00835 ** ## Residuals 20 161.2 8.1 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Embora o termo quadrático incluso no modelo apresente significância (p &lt; 0,05), indicando um bom ajuste, percebe-se que a Falta de Ajuste ainda é singificativa. Além disso, temos graus de liberdade suficiente para testar um modelo de 3° Grau Análise de Regressão - Modelo de 3° Grau Vamos ajustar um modelo do tipo: \\[y_{i}=\\beta _{0}+\\beta _{1}x_{i}+\\beta _{2}x_{i}^2+\\beta _{3}x_{i}^3+\\epsilon\\] ar3 &lt;- aov (lm (resist ~ conc + I(conc^2) + I(conc^3) + concf, data = dados4)) # I(dose^3) corresponde ao termo cúbico summary(ar3) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## conc 1 33.6 33.6 4.171 0.0545 . ## I(conc^2) 1 343.2 343.2 42.582 2.33e-06 *** ## I(conc^3) 1 65.0 65.0 8.062 0.0101 * ## concf 1 33.9 33.9 4.212 0.0535 . ## Residuals 20 161.2 8.1 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Veja que a inclusão do termo cúbico foi significativa, indicando um bom ajuste. Além disso, a Falta de Ajuste já não é significativa! Portanto, temos um modelo bastante consistente. Para concluir a análise, vamos obter a equação ajustada e os seus coeficientes utilizando a função lm da forma convencional, sem incluir os efeitos de tratamentos: reg3 &lt;- lm (resist ~ conc + I(conc^2) + I(conc^3), data = dados4) summary(reg3) ## ## Call: ## lm(formula = resist ~ conc + I(conc^2) + I(conc^3), data = dados4) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.4686 -1.4686 -0.4686 2.6457 4.8886 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 62.611429 39.757436 1.575 0.1302 ## conc -9.011429 5.196609 -1.734 0.0976 . ## I(conc^2) 0.481429 0.216046 2.228 0.0369 * ## I(conc^3) -0.007600 0.002874 -2.644 0.0152 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.048 on 21 degrees of freedom ## Multiple R-squared: 0.6936, Adjusted R-squared: 0.6499 ## F-statistic: 15.85 on 3 and 21 DF, p-value: 1.295e-05 Temos que ficar atentos a esta saída no R: Os coeficientes são estimados adequadamente e os teste de significância estão corretos. Dessa forma a equação ajustada é: \\[y=62.612-9.011x+0.481x^2-0.007x^3\\] - Porém, as estimativas do R^2^ e a estasítica F não correspondem ao cenário ideal! - Isso ocorre porque o termo da Falta de Ajuste é incluído no Erro Experimental. - Além disso, temso que ficar atentos ao R^2^ calculado. A saída do `summary`nesse caso não seria a mais correta. - No caso de dados com repetição o R^2^ mais adequado é: \\[R^{2}= \\frac{SQReg}{SQTrat}=1-\\frac{SQFA}{SQTrat}\\] Sendo assim, temos: R2 &lt;- 1 - (33.9/475.76) R2 ## [1] 0.9287456 Finalmente, podemos fazer um gráfico e adicionar a nossa curva de regressão mais adequada: ggplot(dados4, aes(conc, resist)) + geom_point() + geom_smooth(method=&#39;lm&#39;, se=TRUE, formula = y ~ x + I(x^2)+ I(x^3)) + labs(x=&quot;conc&quot;, y=&quot;resist&quot;) Embora tenhamos empregado um certo esforço para compreender o uso da Regressão Polinomial no contexto de um delineamento experimental, é possível trabalhar de forma bastante simplificada através do pacote Pacote ExpDes.pt Veja abaixo como isso se torna mais simples, embora os conceitos e a interpretação dos resultados permanece a mesma! #install.packages(&quot;ExpDes.pt&quot;) library(ExpDes.pt) ## ## Attaching package: &#39;ExpDes.pt&#39; ## The following objects are masked from &#39;package:agricolae&#39;: ## ## lastC, order.group, tapply.stat dic(dados4$conc, dados4$resist, quali=FALSE) # Muito simples! ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Tratamento 4 475.76 118.94 14.757 9.1279e-06 ## Residuo 20 161.20 8.06 ## Total 24 636.96 ## ------------------------------------------------------------------------ ## CV = 18.88 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos ( Shapiro-Wilk ) ## Valor-p: 0.1817575 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ------------------------------------------------------------------------ ## Teste de homogeneidade de variancia ## valor-p: 0.9197662 ## De acordo com o teste de bartlett a 5% de significancia, as variancias podem ser consideradas homogeneas. ## ------------------------------------------------------------------------ ## ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ======================================== ## Estimativa Erro.padrao tc valor.p ## ---------------------------------------- ## b0 10.9400 2.0862 5.2439 0.00004 ## b1 0.1640 0.0803 2.0424 0.0545 ## ---------------------------------------- ## ## R2 do modelo linear ## -------- ## 0.070666 ## -------- ## ## Analise de variancia do modelo linear ## ======================================================= ## GL SQ QM Fc valor.p ## ------------------------------------------------------- ## Efeito linear 1 33.6200 33.6200 4.17 0.05452 ## Desvios de Regressao 3 442.1400 147.3800 18.29 1e-05 ## Residuos 20 161.2000 8.0600 ## ------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 -39.9886 8.0786 -4.9500 0.0001 ## b1 4.5926 0.6834 6.7203 0 ## b2 -0.0886 0.0136 -6.5255 0 ## ----------------------------------------- ## ## R2 do modelo quadratico ## -------- ## 0.792068 ## -------- ## ## Analise de variancia do modelo quadratico ## ======================================================= ## GL SQ QM Fc valor.p ## ------------------------------------------------------- ## Efeito linear 1 33.6200 33.6200 4.17 0.05452 ## Efeito quadratico 1 343.2143 343.2143 42.58 0 ## Desvios de Regressao 2 98.9257 49.4629 6.14 0.00835 ## Residuos 20 161.2000 8.0600 ## ------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo cubico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 62.6114 37.0268 1.6910 0.1064 ## b1 -9.0114 4.8397 -1.8620 0.0774 ## b2 0.4814 0.2012 2.3927 0.0266 ## b3 -0.0076 0.0027 -2.8394 0.0101 ## ----------------------------------------- ## ## R2 do modelo cubico ## -------- ## 0.928649 ## -------- ## ## Analise de variancia do modelo cubico ## ======================================================= ## GL SQ QM Fc valor.p ## ------------------------------------------------------- ## Efeito linear 1 33.6200 33.6200 4.17 0.05452 ## Efeito quadratico 1 343.2143 343.2143 42.58 0 ## Efeito cubico 1 64.9800 64.9800 8.06 0.01013 ## Desvios de Regressao 1 33.9457 33.9457 4.21 0.05347 ## Residuos 20 161.2000 8.0600 ## ------------------------------------------------------- ## ------------------------------------------------------------------------ "],["experimentos-fatoriais.html", "Capítulo 7 Experimentos Fatoriais 7.1 Introdução 7.2 Tipos de Efeitos 7.3 Casualização em Experimentos Fatoriais 7.4 Efeito do teor de celulose na resistência à tração em embalagens de papel", " Capítulo 7 Experimentos Fatoriais 7.1 Introdução Experimentos Fatoriais são aqueles em que testamos simultaneamente dois ou mais fatores Os diferentes níves de cada fator também são estudados Exemplos: Estudar o efeito da temperatura (30, 40 e 50 °C), do pH (baixo, médio e alto) no rendimento (mol/L) de uma reação química: Dois fatores em estudo: 3 x 3 = 32 = 9 tratamentos Estudar três diferentes tipos de tinta para aviões (A, B e C) e dois diferentes métodos de aplicação (imersão e aspersão) na força de adesão (N/m) Dois fatores em estudo: 3 x 2 = 6 tratamentos Estudar o desempenho de quatro cultivares (A, B, C e D) em três ambientes (Rio Paranaíba, Cristalina e Sorriso) Dois fatores em estudo: 4 x 3 = 12 Veja que, as combinações dos níveis dos fatores é o número de tratamentos no estudo: IJ = N° de tratamentos 7.2 Tipos de Efeitos Efeito Principal: É o efeito individual de cada fator, independente do efeito de outros fatores Interação: É o efeito conjunto para os fatores estudados. Ocorre interação quando o efeito de um fator influencia o efeito de outro fator Exemplo: Considere um experimento fatorial 3x2, em que os fatores em testes são Variedade (V) e Espaçamento (E). Suponha os seguintes resultados fictícios, para a variável altura de plantas (cm), nas seguintes situações: Não há interação entre Fatores: Quando não há interação (ação independente) as diferenças entre os resultados dos níveis de um fator são estatisticamente iguais para todos os níveis do outro fator. Não há interação entre Fatores: Quando há interação significicativa as diferenças entre os níveis de um fator dependem dos níveis do outro fator. 7.3 Casualização em Experimentos Fatoriais Os experimentos fatoriais podem ser delineados tanto de forma inteiramente casualizada, como em blocos completos casualizados. Significa dizer que podem ser organizados em DIC ou DBC Vamos verificar um exemplo em DBC: Exemplo: Suponha um experimento no esquema fatorial com dois fatores (A e B), dispostos em blocos casualizados, com 5 repetições. O fator A possui dois níveis (A1 e A2). O fator B possui três níveis (B1, B2 e B3). Cada combinação (AiBj) dos níveis de cada fator constituem o que chamamos de tratamentos. Como o delineamento utilizado é o DBC, devemos casualizar todos os tratamentos em cada bloco, conforme a figura abaixo: Exemplo 1 Considere que um engenheiro está desenvolvendo um modelo de bateria para uso em condições extremas de temperatura. Para tanto, estão sendo testados três tipos diferentes de materiais. Para verificar o desempenho destes materiais, e testar as condições de temperatura que devem influenciar a vida útil das baterias (em horas), o engenheiro decidiu realizar um ensaio com os três materiais (1, 2 e 3) em três níveis de temperatura (15, 70 e 125 °C). Para realizar o ensaio, conjuntos de quatro baterias foram testados em cada combinação de material e temperatura. Todos os testes foram conduzidos de forma completamente aleatorizada. Os resultados dos experimentos são dados na tabela abaixo. O modelo fatorial com a interação a ser utilizado será: \\[ y_{ijk}=\\mu +\\alpha _{i}+\\beta _{j}+\\alpha \\beta_{ij}+\\epsilon _{ijk}\\] Importação do Data Set (dados5 &lt;- read.table(&quot;dados/dadosfat.txt&quot;,header=T)) ## mat temp rep y ## 1 1 15 1 130 ## 2 1 15 2 155 ## 3 1 15 3 74 ## 4 1 15 4 100 ## 5 1 70 1 34 ## 6 1 70 2 40 ## 7 1 70 3 80 ## 8 1 70 4 75 ## 9 1 125 1 20 ## 10 1 125 2 70 ## 11 1 125 3 82 ## 12 1 125 4 58 ## 13 2 15 1 150 ## 14 2 15 2 188 ## 15 2 15 3 159 ## 16 2 15 4 126 ## 17 2 70 1 136 ## 18 2 70 2 122 ## 19 2 70 3 106 ## 20 2 70 4 115 ## 21 2 125 1 25 ## 22 2 125 2 70 ## 23 2 125 3 58 ## 24 2 125 4 45 ## 25 3 15 1 138 ## 26 3 15 2 110 ## 27 3 15 3 168 ## 28 3 15 4 160 ## 29 3 70 1 174 ## 30 3 70 2 120 ## 31 3 70 3 150 ## 32 3 70 4 139 ## 33 3 125 1 96 ## 34 3 125 2 104 ## 35 3 125 3 82 ## 36 3 125 4 60 Gráficos da Interação Por meio de comandos simples podemos investigar as possíveis interações presentes # Gráfico 1 interaction.plot(dados5$mat, dados5$temp, dados5$y, xlab=&quot;Tipo de Material&quot;, ylab=&quot;Vida Util&quot;) # Gráfico 2 interaction.plot(dados5$temp, dados5$mat, dados5$y, xlab=&quot;Temperatura&quot;, ylab=&quot;Vida Util&quot;) Análise de Variância A ANOVA e todos os testes subsequentes pode ser realizada facilmente pelo pacote ExpDes.pt require(ExpDes.pt) with(data = dados5, fat2.dic(mat, temp, y, quali=c(TRUE, FALSE), mcomp = &quot;tukey&quot;, fac.names = c(&quot;Material&quot;,&quot;Temperatura&quot;) ) ) ## ------------------------------------------------------------------------ ## Legenda: ## FATOR 1: Material ## FATOR 2: Temperatura ## ------------------------------------------------------------------------ ## ## ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr&gt;Fc ## Material 2 14617 5 12.4966 0.0001439 ## Temperatura 2 33185 2 28.3712 0.0000002 ## Material*Temperatura 4 8360 3 3.5738 0.0183064 ## Residuo 27 15791 4 ## Total 35 71954 1 ## ------------------------------------------------------------------------ ## CV = 23.41 % ## ## ------------------------------------------------------------------------ ## Teste de normalidade dos residuos (Shapiro-Wilk) ## valor-p: 0.4849213 ## De acordo com o teste de Shapiro-Wilk a 5% de significancia, os residuos podem ser considerados normais. ## ------------------------------------------------------------------------ ## ## ## ## Interacao significativa: desdobrando a interacao ## ------------------------------------------------------------------------ ## ## Desdobrando Material dentro de cada nivel de Temperatura ## ------------------------------------------------------------------------ ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr.Fc ## Temperatura 2 33185.389 16592.6944 28.3712 0 ## Material:Temperatura 15 2 3566.167 1783.0833 3.0488 0.064 ## Material:Temperatura 70 2 16552.667 8276.3333 14.1514 1e-04 ## Material:Temperatura 125 2 2858.667 1429.3333 2.444 0.1058 ## Residuo 27 15790.750 584.8426 ## Total 35 71953.639 2055.8182 ## ------------------------------------------------------------------------ ## ## ## ## Material dentro do nivel 15 de Temperatura ## ## De acordo com o teste F, as medias desse fator sao estatisticamente iguais. ## ------------------------------------------------------------------------ ## Niveis Medias ## 1 1 114.75 ## 2 2 155.75 ## 3 3 144.00 ## ------------------------------------------------------------------------ ## ## ## Material dentro do nivel 70 de Temperatura ## ------------------------------------------------------------------------ ## Teste de Tukey ## ------------------------------------------------------------------------ ## Grupos Tratamentos Medias ## a 3 145.75 ## a 2 119.75 ## b 1 57.25 ## ------------------------------------------------------------------------ ## ## ## Material dentro do nivel 125 de Temperatura ## ## De acordo com o teste F, as medias desse fator sao estatisticamente iguais. ## ------------------------------------------------------------------------ ## Niveis Medias ## 1 1 57.5 ## 2 2 49.5 ## 3 3 85.5 ## ------------------------------------------------------------------------ ## ## ## ## Desdobrando Temperatura dentro de cada nivel de Material ## ------------------------------------------------------------------------ ## ------------------------------------------------------------------------ ## Quadro da analise de variancia ## ------------------------------------------------------------------------ ## GL SQ QM Fc Pr.Fc ## Material 2 14617.056 7308.5278 12.4966 1e-04 ## Temperatura:Material 1 2 8778.500 4389.2500 7.505 0.0026 ## Temperatura:Material 2 2 23360.167 11680.0833 19.9713 0 ## Temperatura:Material 3 2 9407.167 4703.5833 8.0425 0.0018 ## Residuo 27 15790.750 584.8426 ## Total 35 71953.639 2055.8182 ## ------------------------------------------------------------------------ ## ## ## ## Temperatura dentro do nivel 1 de Material ## ------------------------------------------------------------------------ ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 112.9318 12.9289 8.7349 0 ## b1 -0.5205 0.1555 -3.3479 0.0024 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 1 ## -------- ## 0.746725 ## -------- ## ## Analise de variancia do modelo linear ## ============================================================ ## GL SQ QM Fc valor.p ## ------------------------------------------------------------ ## Efeito linear 1 6,555.1250 6,555.1250 11.21 0.00241 ## Desvios de Regressao 1 2,223.3750 2,223.3750 3.8 0.06166 ## Residuos 27 15,790.7500 584.8426 ## ------------------------------------------------------------ ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 140.4545 19.1419 7.3376 0 ## b1 -1.8568 0.7028 -2.6420 0.0135 ## b2 0.0095 0.0049 1.9498 0.0617 ## ----------------------------------------- ## ## R2 do modelo quadratico ## - ## 1 ## - ## ## Analise de variancia do modelo quadratico ## ============================================================ ## GL SQ QM Fc valor.p ## ------------------------------------------------------------ ## Efeito linear 1 6,555.1250 6,555.1250 11.21 0.00241 ## Efeito quadratico 1 2,223.3750 2,223.3750 3.8 0.06166 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 27 15,790.7500 584.8426 ## ------------------------------------------------------------ ## ------------------------------------------------------------------------ ## ## ## Temperatura dentro do nivel 2 de Material ## ------------------------------------------------------------------------ ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 175.9470 12.9289 13.6088 0 ## b1 -0.9659 0.1555 -6.2133 0 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 2 ## -------- ## 0.966522 ## -------- ## ## Analise de variancia do modelo linear ## ============================================================= ## GL SQ QM Fc valor.p ## ------------------------------------------------------------- ## Efeito linear 1 22,578.1200 22,578.1200 38.61 0 ## Desvios de Regressao 1 782.0417 782.0417 1.34 0.25766 ## Residuos 27 15,790.7500 584.8426 ## ------------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 159.6240 19.1419 8.3390 0 ## b1 -0.1733 0.7028 -0.2466 0.8070 ## b2 -0.0057 0.0049 -1.1564 0.2577 ## ----------------------------------------- ## ## R2 do modelo quadratico ## - ## 1 ## - ## ## Analise de variancia do modelo quadratico ## ============================================================= ## GL SQ QM Fc valor.p ## ------------------------------------------------------------- ## Efeito linear 1 22,578.1200 22,578.1200 38.61 0 ## Efeito quadratico 1 782.0417 782.0417 1.34 0.25766 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 27 15,790.7500 584.8426 ## ------------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## ## Temperatura dentro do nivel 3 de Material ## ------------------------------------------------------------------------ ## Ajuste de modelos polinomiais de regressao ## ------------------------------------------------------------------------ ## ## Modelo Linear ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 162.3106 12.9289 12.5541 0 ## b1 -0.5318 0.1555 -3.4210 0.0020 ## ----------------------------------------- ## ## R2 do modelo linear ## -------- ## 3 ## -------- ## 0.727584 ## -------- ## ## Analise de variancia do modelo linear ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 6,844.5000 6,844.5000 11.7 0.002 ## Desvios de Regressao 1 2,562.6670 2,562.6670 4.38 0.04585 ## Residuos 27 15,790.7500 584.8426 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ ## ## Modelo quadratico ## ========================================= ## Estimativa Erro.padrao tc valor.p ## ----------------------------------------- ## b0 132.7624 19.1419 6.9357 0 ## b1 0.9029 0.7028 1.2847 0.2098 ## b2 -0.0102 0.0049 -2.0933 0.0458 ## ----------------------------------------- ## ## R2 do modelo quadratico ## - ## 1 ## - ## ## Analise de variancia do modelo quadratico ## =========================================================== ## GL SQ QM Fc valor.p ## ----------------------------------------------------------- ## Efeito linear 1 6,844.5000 6,844.5000 11.7 0.002 ## Efeito quadratico 1 2,562.6670 2,562.6670 4.38 0.04585 ## Desvios de Regressao 0 0 0 0 1 ## Residuos 27 15,790.7500 584.8426 ## ----------------------------------------------------------- ## ------------------------------------------------------------------------ 7.3.1 Outros Gráficos! #install.packages(&quot;tidyverse&quot;) library(tidyverse) ## ── Attaching core tidyverse packages ───────────────── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ lubridate 1.9.3 ✔ tibble 3.2.1 ## ✔ purrr 1.0.2 ✔ tidyr 1.3.1 ## ── Conflicts ──────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors dados6 &lt;- dados5 %&gt;% group_by(mat, temp) %&gt;% summarise(media = mean(y,na.rm=T)) ## `summarise()` has grouped output by &#39;mat&#39;. You can ## override using the `.groups` argument. dados6 ## # A tibble: 9 × 3 ## # Groups: mat [3] ## mat temp media ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 15 115. ## 2 1 70 57.2 ## 3 1 125 57.5 ## 4 2 15 156. ## 5 2 70 120. ## 6 2 125 49.5 ## 7 3 15 144 ## 8 3 70 146. ## 9 3 125 85.5 ggplot(dados6, aes(mat, media)) + geom_col(alpha = 0.8, position = &quot;dodge&quot;) + facet_wrap(~temp) + theme_bw(16) + theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) #Relatório Final AGR 194 - Estatística Experimental 7.4 Efeito do teor de celulose na resistência à tração em embalagens de papel 7.4.1 Introdução A produção de papel desempenha um papel fundamental na sociedade contemporânea, sendo um dos pilares da comunicação escrita e da preservação de informações (Hubbe et al., 2019). A qualidade do papel, por sua vez, está intrinsecamente ligada às propriedades da celulose, principal componente proveniente da madeira, que serve como matéria-prima para a fabricação do papel (Aspinwall et al., 2017). Este artigo visa explorar a relação entre a resistência à tração do papel e os diferentes teores de celulose presentes na madeira utilizada na sua produção. A celulose, um polissacarídeo composto por longas cadeias de glicose, é o principal componente estrutural das fibras vegetais, sendo extraída da madeira por meio de processos industriais (Pelissari et al., 2018). Diversos fatores influenciam a qualidade da celulose, tais como a espécie da árvore, o método de extração e o processamento subsequente (Basta et al., 2019). Estudos anteriores destacaram a importância da celulose na determinação das propriedades físicas e mecânicas do papel, sendo a resistência à tração uma característica crucial para garantir a durabilidade e desempenho adequado do material (Gurnagul &amp; Page, 1992). Ao longo das últimas décadas, pesquisadores têm se dedicado a compreender como variações nos teores de celulose na madeira afetam a resistência à tração do papel resultante (Aspinwall et al., 2017). Uma série de investigações tem indicado que diferentes tipos de madeira possuem composições celulósicas distintas, o que influencia diretamente na qualidade e resistência do papel produzido (Basta et al., 2019). Essas descobertas têm implicações significativas para a indústria de papel, fornecendo insights valiosos para otimizar a escolha da matéria-prima e os processos de produção. Este artigo busca contribuir para o entendimento aprofundado da relação entre teores de celulose na madeira e a resistência à tração do papel, consolidando informações provenientes de estudos prévios e explorando novas perspectivas (Hubbe et al., 2019). Ao fazê-lo, pretende-se fornecer subsídios que possam orientar a indústria na tomada de decisões mais informadas e sustentáveis, promovendo avanços significativos na produção de papel. 7.4.2 Materiais e Métodos O experimento foi conduzido utilizando um delineamento inteiramente casualizado, onde os diferentes níveis de concentração de celulose na madeira foram atribuídos aleatoriamente aos corpos de prova. Diferentes tipos de madeira foram utilizados, cada uma com concentrações variadas de celulose. A escolha da madeira foi baseada em considerações sobre a composição celulósica, levando em conta a influência desta na resistência do papel (Basta et al., 2019). A variável independente principal foi a concentração de celulose na madeira, com quatro níveis distintos: 5%, 10%, 15%, e 20%. Seis corpos de prova foram fabricados para cada nível de concentração, totalizando 24 amostras. A fabricação dos corpos de prova foi realizada em uma planta piloto, garantindo condições controladas e representativas do processo industrial de produção de papel (Figura 1). Os 24 corpos de prova foram submetidos a testes de resistência à tração em um equipamento de laboratório. Os resultados foram registrados em psi (libra/polegada²), proporcionando dados quantitativos sobre a resistência do papel em diferentes concentrações de celulose. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
